import json
import jydoop
import healthreportutils
import random



setupjob = healthreportutils.setupjob

def skip_local_output():
    return True

minimalActiveFhrDaysEntrySet = set(["org.mozilla.crashes.crashes","org.mozilla.appSessions.previous"])





'''
MAPPER:
need to get a fingerprint for each record.
along with each fingerprint (as key), pass the following as value:
(1) the complete raw FHR json
(2) the last date observed (thisPingDate) in the record (which will be used in the reducer to pick the head record)
(3) the number of sessions observed in the last day (which will be used to break ties if there are multiple records with the same last date observed)

REDUCER:
to find the head record for each fingerprint:
a) if there is a unique record with a thisPingDate greater than that in any other record with this fingerprint, then that record is head
b) if there are ties in (a), pick the record with the maximum number of sessionsOnThisPingDate
c) if there are ties after (b), pick the record with the maximum currentSessionTime
d) if that still results in a tie, pick one at random (????? not sure about this... could also discard the fingerprint, or try breaking ties with something else)

this will only work correctly for fingerprints that are truly generated by one instance; for other situations (copied profiles) the results will not be correct
'''



def map(fhrDocId, rawJsonIn, context):

    try:
        payload = json.loads(rawJsonIn)
    except KeyError:
        #context.write(("error","bad_payload"),1)
        #context.write("global_count",1)
        return

    try: #was getting errors finding packets without a version field, so had to wrap this test in a try block
        if not (payload["version"]==2):
            return
    except KeyError:
        #context.write(("error","no_version"),1)
        #context.write("global_count",1)
        return

    try:
        thisPingDate = payload["thisPingDate"]
    except KeyError:
        #context.write(("error","no_thisPingDate"),1)
        #context.write("global_count",1)
        return

    try:
        lastPingDate = payload["lastPingDate"]
    except KeyError:
        #context.write(("error","no_lastPingDate"),1)
        #context.write("global_count",1)
        lastPingDate = None


    try:
      updateChannel = payload["geckoAppInfo"]["updateChannel"].strip()
    except:
        try:
            updateChannel = payload["data"]["last"]["org.mozilla.appInfo.appinfo"]["updateChannel"].strip()
        except:
            updateChannel='no_channel'
    if not (updateChannel in ["nightly","aurora","beta"]):
        #context.write(("error","wrong_channel"),1)
        #context.write("global_count",1)
        return


    try: 
        buildIdAt_thisPingDate = payload["geckoAppInfo"]["appBuildID"].strip()
    except:
        try:
            buildIdAt_thisPingDate = payload["data"]["last"]["org.mozilla.appInfo.appinfo"]["appBuildID"].strip()
        except:
            buildIdAt_thisPingDate='no_buildIdAt_thisPingDate'


    try:
        os = payload["geckoAppInfo"]["os"]
    except KeyError:
        try:
            os = payload["data"]["last"]["org.mozilla.appInfo.appinfo"]["os"].strip()
        except KeyError:
            os = "no_os"


    try:
        profileCreation = payload["data"]["last"]["org.mozilla.profile.age"]["profileCreation"]
    except KeyError:
        profileCreation = "no_profileCreation"


    try:
        country =payload["geoCountry"]
    except KeyError:
        country="no_country"

    try:
        memory =payload["data"]["last"]["org.mozilla.sysinfo.sysinfo"]["memoryMB"]
    except KeyError:
        memory="no_memory"


    try:
        dataDays = payload["data"]["days"].keys()
    except KeyError:
        dataDays = None


    try:
        numAppSessionsPreviousOnThisPingDate=len(payload["data"]["days"][thisPingDate]['org.mozilla.appSessions.previous']["main"])
    except KeyError:
        numAppSessionsPreviousOnThisPingDate = 0

    try:
        currentSessionTime=payload["data"]["last"]['org.mozilla.appSessions.current']["totalTime"]
    except KeyError:
        currentSessionTime = 0



    #set up the complete list of observed active days. We will need to go back and remove entries from before the FHR activation date.
    activeDays = [thisPingDate]
    activeDays = activeDays+dataDays if dataDays else activeDays
    activeDays = activeDays+[lastPingDate] if lastPingDate else activeDays



    #find the FHR activation date
    if dataDays:
        #if there are dataDays entries, get the first one on which FHR is active
        fhrActiveDataDaysList = [day for day in dataDays if not (set(payload["data"]["days"][day].keys())<=minimalActiveFhrDaysEntrySet)]
        # if there are fhr active days, find the first of them; if there are no entries in dataDays that have these fields, perhaps we are looking at an instance that has just had FHR activated, and has some old crashes? in the latter case get the earliest day in activeDays
        if fhrActiveDataDaysList:
            fhrActivationDate=min(fhrActiveDataDaysList)
        else:
            fhrActivationDate = min(activeDays)
    else:
        #if there are not any dataDays entries, get the earliest day in activeDays, which will be the min of thisPingDate and lastPingDate (and hopefully lastPingDate should not exist in this case...)
        fhrActiveDataDaysList = []
        fhrActivationDate = min(activeDays)

    #find the days active since FHR code became active.
    activeDaysSinceFhr = [date for date in activeDays if date>=fhrActivationDate]



    try:
        firstFhrActiveDayData = str( payload["data"]["days"][min(activeDaysSinceFhr)] )
    except KeyError:
        firstFhrActiveDayData = "no_firstFhrActiveDayData"


    context.write(  (os,
                  updateChannel,
                  country,
                  str(memory),
                  str(profileCreation),
                  min(activeDaysSinceFhr),
                  fhrActivationDate,
                  firstFhrActiveDayData)

                  ,(thisPingDate, numAppSessionsPreviousOnThisPingDate, currentSessionTime, rawJsonIn, fhrDocId) )














def reduce(k, vIter, cx):

    maxRecordTup = None #initialize as a None
    maxRecordTupList = None
    maxDate="0000-00-00"
    maxSessionsOnMaxDate=0
    maxSessTimeOnMaxDate=0

    maxRecordTup = ("0000-00-00",0,0)
    for valTup in vIter:
        if valTup>maxRecordTup:
            #if this is the maximal record, update the maxRecordTup and reset the maxRecordTupList
            maxRecordTupList=[valTup]
            maxRecordTup=valTup[0:3]
        elif valTup==maxRecordTup:
            #if this record is tied for maximal record, add it to the list of record tups that tie for max
            maxRecordTupList+=[valTup]


    if len(maxRecordTupList)==1:
        maxRecordTup = maxRecordTupList[0]

    if len(maxRecordTupList)>1:
        print [tup[0:3] for tup in maxRecordTupList],len(maxRecordTupList)
        maxRecordTup = random.choice(maxRecordTupList)
        #cx.write( "NON_UNIQUE_HEAD_RECORD" ,maxRecordTup)


    randKey = random.random()
    if randKey < 0.0005:
        cx.write( maxRecordTup[4] , maxRecordTup[3] )











